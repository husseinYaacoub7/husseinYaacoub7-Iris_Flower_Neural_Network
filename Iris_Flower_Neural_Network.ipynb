{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoxnhCC8MwAi",
        "outputId": "6669ce23-8fd8-4349-f87a-07d076c681c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 142ms/step - accuracy: 0.2760 - loss: 1.7097 - val_accuracy: 0.1667 - val_loss: 1.2985 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3411 - loss: 1.5923 - val_accuracy: 0.1667 - val_loss: 1.2914 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2773 - loss: 1.6050 - val_accuracy: 0.1667 - val_loss: 1.2865 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3255 - loss: 1.5840 - val_accuracy: 0.2083 - val_loss: 1.2809 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3594 - loss: 1.6247 - val_accuracy: 0.2083 - val_loss: 1.2764 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3711 - loss: 1.6762 - val_accuracy: 0.2083 - val_loss: 1.2683 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3802 - loss: 1.6140 - val_accuracy: 0.2083 - val_loss: 1.2649 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4544 - loss: 1.4532 - val_accuracy: 0.2083 - val_loss: 1.2613 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2812 - loss: 1.5877 - val_accuracy: 0.2083 - val_loss: 1.2591 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3372 - loss: 1.5113 - val_accuracy: 0.2083 - val_loss: 1.2561 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3073 - loss: 1.5405 - val_accuracy: 0.2083 - val_loss: 1.2519 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4544 - loss: 1.4424 - val_accuracy: 0.2083 - val_loss: 1.2487 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3555 - loss: 1.5094 - val_accuracy: 0.2083 - val_loss: 1.2441 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3424 - loss: 1.4097 - val_accuracy: 0.2500 - val_loss: 1.2398 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4167 - loss: 1.3466 - val_accuracy: 0.3333 - val_loss: 1.2336 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4010 - loss: 1.4259 - val_accuracy: 0.3333 - val_loss: 1.2277 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4010 - loss: 1.3598 - val_accuracy: 0.3333 - val_loss: 1.2229 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3451 - loss: 1.4403 - val_accuracy: 0.3333 - val_loss: 1.2149 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4180 - loss: 1.3641 - val_accuracy: 0.4583 - val_loss: 1.2065 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3542 - loss: 1.3723 - val_accuracy: 0.4583 - val_loss: 1.2011 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3568 - loss: 1.3530 - val_accuracy: 0.4583 - val_loss: 1.1967 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4271 - loss: 1.4130 - val_accuracy: 0.5000 - val_loss: 1.1907 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4388 - loss: 1.2779 - val_accuracy: 0.5000 - val_loss: 1.1854 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4479 - loss: 1.2518 - val_accuracy: 0.4583 - val_loss: 1.1797 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4141 - loss: 1.3247 - val_accuracy: 0.4583 - val_loss: 1.1720 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4492 - loss: 1.4189 - val_accuracy: 0.5000 - val_loss: 1.1634 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4688 - loss: 1.2678 - val_accuracy: 0.5000 - val_loss: 1.1563 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4714 - loss: 1.2680 - val_accuracy: 0.5000 - val_loss: 1.1508 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4297 - loss: 1.2943 - val_accuracy: 0.5417 - val_loss: 1.1453 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4857 - loss: 1.2726 - val_accuracy: 0.5417 - val_loss: 1.1371 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5013 - loss: 1.2077 - val_accuracy: 0.5417 - val_loss: 1.1290 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5039 - loss: 1.2031 - val_accuracy: 0.5417 - val_loss: 1.1214 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4141 - loss: 1.2804 - val_accuracy: 0.5417 - val_loss: 1.1145 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4766 - loss: 1.1514 - val_accuracy: 0.5417 - val_loss: 1.1100 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5521 - loss: 1.0885 - val_accuracy: 0.5833 - val_loss: 1.1037 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4583 - loss: 1.0919 - val_accuracy: 0.5833 - val_loss: 1.0953 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5378 - loss: 1.1352 - val_accuracy: 0.5833 - val_loss: 1.0898 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4831 - loss: 1.1601 - val_accuracy: 0.6250 - val_loss: 1.0793 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5234 - loss: 1.0564 - val_accuracy: 0.6667 - val_loss: 1.0735 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4596 - loss: 1.2596 - val_accuracy: 0.5833 - val_loss: 1.0690 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5013 - loss: 1.1081 - val_accuracy: 0.5833 - val_loss: 1.0646 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4935 - loss: 1.1476 - val_accuracy: 0.5833 - val_loss: 1.0610 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5586 - loss: 1.1358 - val_accuracy: 0.5833 - val_loss: 1.0538 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6029 - loss: 1.0799 - val_accuracy: 0.6667 - val_loss: 1.0435 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5833 - loss: 1.0166 - val_accuracy: 0.6667 - val_loss: 1.0370 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5729 - loss: 1.0708 - val_accuracy: 0.6667 - val_loss: 1.0311 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6146 - loss: 1.0338 - val_accuracy: 0.6667 - val_loss: 1.0251 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4792 - loss: 1.2048 - val_accuracy: 0.6667 - val_loss: 1.0218 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5247 - loss: 1.0783 - val_accuracy: 0.6667 - val_loss: 1.0139 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5768 - loss: 1.0432 - val_accuracy: 0.6667 - val_loss: 1.0034 - learning_rate: 0.0010\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9667 - loss: 0.9238\n",
            "Test loss: 0.9237601161003113, Test accuracy: 0.9666666388511658\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/IRIS.csv')\n",
        "\n",
        "# Encode the target variable\n",
        "encoder = LabelEncoder()\n",
        "data['species'] = encoder.fit_transform(data['species'])\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "features = data.drop('species', axis=1)\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# Prepare the data\n",
        "X = scaled_features\n",
        "y = to_categorical(data['species'])  # One-hot encode target\n",
        "\n",
        "# Split the dataset into training and testing sets (80/20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model using an Input layer\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),  # Make sure X_train is already defined and loaded correctly before this step\n",
        "    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),\n",
        "    BatchNormalization(),\n",
        "    Dense(8, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),\n",
        "    BatchNormalization(),\n",
        "    Dense(y_train.shape[1], activation='softmax')  # Ensure y_train is defined and one-hot encoded\n",
        "])\n",
        "\n",
        "# Compile the model with updated learning rate argument\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[reduce_lr, early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
      ]
    }
  ]
}